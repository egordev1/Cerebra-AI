"""
–Ø–¥—Ä–æ —Å–∏—Å—Ç–µ–º—ã Cerebra AI
–§–∞–π–ª: core.py - –ì–ª–∞–≤–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä AI —Å–∏—Å—Ç–µ–º—ã, —É–ø—Ä–∞–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—è–º–∏, –æ–±—É—á–µ–Ω–∏–µ–º, —á–∞—Ç–æ–º
"""
import torch
import os
import sys
import io

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ UTF-8 –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except (AttributeError, ValueError):
        pass  # –ï—Å–ª–∏ —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ

from .logger_config import logger

class Cerebra:
    def __init__(self):
        self.name = "Cerebra"
        self.version = "1.0.0"
        self.active_model = None
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            logger.info(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.get_device_name(0)}")
            logger.info(f"üìä CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
        else:
            self.device = torch.device('cpu')
            logger.warning("‚ö†Ô∏è CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
        
        logger.info(f"üß† –ó–∞–ø—É—â–µ–Ω–∞ {self.name} AI System")
        logger.info(f"üìä –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        print(f"üß† –ó–∞–ø—É—â–µ–Ω–∞ {self.name} AI System")
        print(f"üìä –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
    
    def load_model(self, model_name="Synthesis-L1"):
        try:
            if model_name == "Synthesis-L1":
                from .models.main_model import SynthesisL1
                logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name} –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ {self.device}...")
                self.active_model = SynthesisL1(use_gpt=True)
                
                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                if hasattr(self.active_model, 'gpt_model'):
                    self.active_model.gpt_model = self.active_model.gpt_model.to(self.device)
                self.active_model = self.active_model.to(self.device)
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_name} –Ω–∞ {self.device}")
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
            else:
                logger.error(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                print(f"‚ùå –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return None
            return self.active_model
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–∏: {e}", exc_info=True)
            # Fallback –Ω–∞ CPU –µ—Å–ª–∏ CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
            if self.device.type == 'cuda':
                logger.warning("–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ CPU –≤–º–µ—Å—Ç–æ CUDA")
                self.device = torch.device('cpu')
                try:
                    from .models.main_model import SynthesisL1
                    self.active_model = SynthesisL1().to(self.device)
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_name} –Ω–∞ CPU (fallback)")
                    return self.active_model
                except Exception as e2:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –Ω–∞ CPU: {e2}", exc_info=True)
            return None
    
    def chat(self, message, use_web_search=False):
        """
        –û–±—â–µ–Ω–∏–µ —Å –ò–ò
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            use_web_search: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ–±-–ø–æ–∏—Å–∫ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        """
        if not self.active_model:
            logger.warning("–ü–æ–ø—ã—Ç–∫–∞ —á–∞—Ç–∞ –±–µ–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
            return "‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å: ai.load_model()"
        
        logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è: {message}")
        
        # –í–µ–±-–ø–æ–∏—Å–∫ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if use_web_search:
            try:
                from .web_search import web_searcher
                web_answer = web_searcher.get_answer_from_web(message)
                if web_answer:
                    logger.info("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç –∏–∑ –≤–µ–±-–ø–æ–∏—Å–∫–∞")
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–º–µ–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                    if hasattr(self.active_model, 'dialogue_collector') and self.active_model.dialogue_collector:
                        self.active_model.dialogue_collector.add_exchange(message, web_answer)
                    return web_answer
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤–µ–±-–ø–æ–∏—Å–∫–∞: {e}")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª—å—é
        response = self.active_model.process(message)
        logger.debug(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: {response}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
        if hasattr(self.active_model, 'dialogue_collector') and self.active_model.dialogue_collector:
            self.active_model.dialogue_collector.add_exchange(message, response)
        
        return response
    
    def get_dialogue_stats(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∏–∞–ª–æ–≥–æ–≤"""
        if not self.active_model or not hasattr(self.active_model, 'dialogue_collector'):
            return {'total_dialogues': 0, 'total_exchanges': 0}
        if self.active_model.dialogue_collector:
            return self.active_model.dialogue_collector.get_statistics()
        return {'total_dialogues': 0, 'total_exchanges': 0}
    
    def real_training(self, epochs=10, batch_size=4):
        if not self.active_model:
            logger.error("–ü–æ–ø—ã—Ç–∫–∞ –æ–±—É—á–µ–Ω–∏—è –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏")
            print("‚ùå –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏")
            return False
        
        try:
            if hasattr(self.active_model, 'real_train'):
                logger.info(f"üöÄ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ {epochs} —ç–ø–æ—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ {self.device}...")
                print(f"üöÄ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ {epochs} —ç–ø–æ—Ö...")
                success = self.active_model.real_train(epochs=epochs, batch_size=batch_size)
                
                if success:
                    logger.info("üéâ –û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                    print("üéâ –û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
                    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
                    test_texts = ["–∫–∞–∫ –¥–µ–ª–∞", "–≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "—á—Ç–æ –Ω–æ–≤–æ–≥–æ", "—Ö–æ—Ä–æ—à–∞—è —Ä–∞–±–æ—Ç–∞"]
                    logger.info("üß™ –¢–µ—Å—Ç –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:")
                    print("\nüß™ –¢–µ—Å—Ç –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:")
                    for text in test_texts:
                        response = self.chat(text)
                        logger.debug(f"–¢–µ—Å—Ç: '{text}' -> {response}")
                        print(f"   '{text}' -> {response}")
                else:
                    logger.error("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–∏–ª–æ—Å—å –Ω–µ—É–¥–∞—á–µ–π")
                return success
            else:
                logger.error("–ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ")
                print("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ")
                return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}", exc_info=True)
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False
    
    def save_model(self, path="models/synthesis_l1.pth"):
        if not self.active_model:
            logger.error("–ü–æ–ø—ã—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏")
            print("‚ùå –ù–µ—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return False
        
        try:
            os.makedirs(os.path.dirname(path), exist_ok=True)
            logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ {path}...")
            
            # –î–ª—è GPT –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º gpt_model
            if hasattr(self.active_model, 'gpt_model'):
                torch.save({
                    'gpt_model_state_dict': self.active_model.gpt_model.state_dict(),
                    'model_id': self.active_model.model_id,
                    'version': self.active_model.version,
                    'is_trained': getattr(self.active_model, 'is_trained', True),
                }, path)
                logger.info("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ GPT –º–æ–¥–µ–ª—å")
            else:
                torch.save(self.active_model.state_dict(), path)
            
            logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {path}")
            print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {path}")
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏: {e}", exc_info=True)
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")
            return False
    
    def info(self):
        info_text = f"""
üß† {self.name} AI System v{self.version}
üìä –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}

–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:
‚Ä¢ Synthesis-L1 - GPT —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å (—Ç–µ–∫—Å—Ç–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è)
‚Ä¢ Synthesis-L2 - –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ
‚Ä¢ Synthesis-L3 - –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ
"""
        if self.active_model:
            model_info = self.active_model.get_info()
            info_text += f"\nüéØ –ê–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å: {model_info['model_id']}"
            info_text += f"\nüìà –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {model_info['parameters']:,}"
        
        return info_text