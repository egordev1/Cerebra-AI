# 🧠 Cerebra AI

Современная AI система на основе GPT-подобного трансформера с поддержкой веб-поиска и автоматического обучения на реальных диалогах.

## ✨ Особенности

- 🚀 **GPT Transformer архитектура** - настоящая нейросеть для генерации текста
- 🌐 **Веб-поиск** - автоматический поиск информации в интернете
- 📚 **Автоматическое обучение** - модель обучается на реальных диалогах из чата
- 💾 **Сохранение прогресса** - все диалоги сохраняются для обучения
- 🎯 **Генеративное обучение** - next token prediction как в GPT/ChatGPT

## 📦 Установка

```bash
pip install -r requirements.txt
```

## 🚀 Запуск

```bash
python main.py
```

## 🎮 Возможности

1. **💬 Чат с ИИ** - общение с моделью с опциональным веб-поиском
2. **🎓 Обучение** - обучение на реальных диалогах из чата
3. **🌐 Поиск в интернете** - прямой поиск информации
4. **ℹ️ Информация** - данные о системе и модели
5. **💾 Сохранение** - сохранение обученной модели
6. **🗑️ Очистка** - очистка истории диалогов

## 🏗️ Архитектура модели Synthesis-L1

- **Тип**: GPT Transformer (авторегрессивная генерация текста)
- **Размерность**: 512 dim
- **Attention Heads**: 8
- **Слои**: 6 трансформерных блоков
- **Параметров**: ~29 миллионов
- **Токенизатор**: Русский язык, до 10K токенов
- **Обучение**: Next token prediction на реальных диалогах
- **Генерация**: Top-k + Top-p (nucleus) sampling

## 📁 Структура проекта и описание файлов

### Корневые файлы

- **`main.py`** - Главный запускаемый файл приложения. Содержит меню, интерфейс пользователя, управление режимами работы (чат, обучение, поиск)
- **`requirements.txt`** - Список зависимостей проекта (PyTorch, requests, beautifulsoup4 и др.)
- **`README.md`** - Документация проекта (этот файл)
- **`cleanup.py`** - Скрипт для очистки всех пользовательских данных и сброса до заводских настроек
- **`setup.py`** - Скрипт для установки пакета

### Папка `cerebra/` - Основной код проекта

#### Главные модули

- **`core.py`** - Ядро системы. Класс `Cerebra` - главный контроллер всей AI системы. Управляет загрузкой модели, обучением, чатом, сохранением модели. Это центральная точка управления

- **`logger_config.py`** - Настройка логирования. Создает логгеры, настраивает запись в файлы и консоль. Все события системы записываются через этот модуль

#### Модули функциональности

- **`web_search.py`** - Веб-поиск в интернете. Класс `WebSearcher` для поиска информации через DuckDuckGo. Используется для получения актуальных данных из интернета

- **`dialogue_training.py`** - Автоматическое обучение на диалогах. Класс `DialogueCollector` собирает все диалоги из чата и сохраняет их для обучения модели. Это ключевой компонент для автоматического улучшения модели

- **`utils.py`** - Вспомогательные утилиты (информация о системе, вывод статистики и т.д.)

### Папка `cerebra/models/` - Модели нейросети

- **`main_model.py`** - Главная модель Synthesis-L1. Это обертка, которая управляет GPT трансформером или LSTM моделью. Обрабатывает входные тексты, генерирует ответы, интегрирует токенизатор. **Это основной мозг ИИ**

- **`gpt_model.py`** - GPT Transformer модель (главный мозг ИИ). Содержит:
  - `GPTTransformer` - основная GPT архитектура
  - `TransformerBlock` - блоки трансформера с Multi-Head Attention
  - `MultiHeadAttention` - механизм внимания
  - `PositionalEncoding` - позиционное кодирование
  - Метод `generate()` - генерация текста
  
- **`training.py`** - Обучение GPT модели. Содержит:
  - `TextDataset` - датасет для обучения
  - `prepare_training_data()` - подготовка данных из диалогов
  - `train_gpt_model()` - функция обучения модели на реальных данных

- **`tokenizer.py`** - Токенизатор для русского языка. Класс `SimpleTokenizer` для преобразования текста в токены и обратно. Строит словарь из обучающих данных

- **`__init__.py`** - Инициализация пакета models

### Папка `cerebra/examples/` - Примеры использования

- **`basic_usage.py`** - Пример базового использования Cerebra AI

### Другие файлы

- **`logs/`** - Папка с логами работы системы
- **`models/`** - Папка для сохранения обученных моделей и токенизаторов
- **`training_data/`** - Папка с собранными диалогами для обучения

## 📝 Как работает обучение

1. Вы общаетесь с ИИ в чате
2. Все диалоги автоматически сохраняются в `training_data/dialogues.json`
3. При обучении (пункт 2 в меню) модель использует эти диалоги
4. Модель обучается на предсказании следующего токена (как в GPT)
5. Чем больше диалогов - тем лучше модель

## 🔧 Требования

- Python 3.8+
- PyTorch 2.0+
- requests
- beautifulsoup4
- lxml

## 🐛 Исправленные проблемы

- ✅ Исправлена ошибка размерностей тензоров в генерации
- ✅ Улучшена обработка ошибок при генерации
- ✅ Оптимизирована длина генерации для более быстрой работы

## 📄 Лицензия

MIT License
